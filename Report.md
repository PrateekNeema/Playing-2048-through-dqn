# Gaming Meets AI

### Mentee : Prateek Neema
### Roll No : 20D070061
### Department : Electrical

### Mentors : Ankit Kumar Jain and Silky Kumari

 
 
### TASK 1

We had a session where we were intorduced to version control using git and github.
During the course of the project, I have become quite comfortable with them and use this [cheat sheet ](https://www.notion.so/Version-Control-with-Git-51504dd7484e446aa5f5a50b757a29b4#ceac8ded0f034d5089386a8de0ab1563) wherever I need version control.
It was my first time using git and github and I found it extremely useful and efficient.

### TASK 2

As we were going to use python to code the preject,the second task was to get used to pyhton and its diffeernt modules.

I watched several youtube videos, read various tutorials on the web, and practiced many programs over the course of the month of April.

Links of some of the sources i used:

- [Python Basics Tutorial on youtube](https://www.youtube.com/watch?v=rfscVS0vtbw&list=LL&index=19)
- [Complete Numpy Tutorial](https://www.youtube.com/watch?v=GB9ByFAIAH4&list=LL&index=11)
- [Mtaplotlib tutorials for numpy and pandas](https://www.youtube.com/watch?v=0P7QnIQDBJY&list=LL&index=6)
- [Complete pandas tutorial](https://www.youtube.com/watch?v=vmEHCJofslg&list=LL&index=7)
- [python and numpy basics](https://www.learnpython.org/)
- [Python docs and the docs of different modules](https://docs.python.org/3/) 

I used many more sources to learn from but these are some of the main ones.

We were also given a coding assignmnet by the mentors.Link to my solns the assignment problems is [here](https://github.com/akj0811/SoC---Gaming-Meets-AI/tree/master/Assignment/Codes/Prateek).

I was extremely happy with all that I had learnt in that period and am eager to learn more.The power of python was already making me feel like giant.
This was one of my major gains from the project.

### TASK 3

We then proceeded to the [deep learning book](https://www.deeplearningbook.org/) by Ian Goodfellow,Yoshua Bengio and Aaron Courville(MIT).The text was a one stop source for everything about deep learning.We would be needing only the bsaics of DL, so we were advised to read at least the first 6 chapters.

The first 4 chapters,namely, the introduction,Linear Algebr,Probability and Information Theory and Numerical Computation dealt with the mathematics and therotical parts that we one would need to know and understand in order to learn about AI.
The fifth chapter,Machine Learning Basics, dealt with ML basics incuding variius algorithms,scenarios,models,shortcomings and solutions.
The sixth chapter,Deep Feedforward Networks, was the the actual begginnng of DL.It explained concepts of neurons,layers,linear and non linear relations,complete algotritms,training networks,etc.It gave me all that I needed for the project and even more.

### TASK 4

Our next stop was the reinfrocement learning book by barto and sutton.It is concsidered as the best book out there to learn RL.I spent almost the whole of May on this book.

We were asked to read the first 6 chapters from the book.They consisted of most of the concepts and algorithms that are currently being used by RL agents around the world. 

1. The reinforcement learning problem : This was an  introductin to RL,its uses,pros and cons and some examples to understand the simple ideas behind it.It also set up the reinforcemnt learning problem that would be solved thorughout the book.

2. Multi-arm Bandits : We considered some very simplified versions of the above problem and tried solving them using different methods and ideas.

3. Finite Markov Decision Processes : We gave the definition of Markov states and Markov decison processes.We went on to see that putting this condition on states made it possibe to find a solution the RL problem.Even if the condtion wasn't follwed strictly,the results coud be used and thus it gave a very viable way forward.

The next thre chapters dealt with the three posiible ways to proceed solving the RL problem.

4. Dynamic Programming ; We discussed the concept of dynamic programming and how it could be applied.

5. Monte Carlo Methods : We learnt about these methods and how tey couud be usedn pur case.

6. Temporal-Difference Learning : It dealt wth the various methods like Q-learning and Sarsa that are very popular in RL in today's world.

Each chapter required a decent amount of time.It took me many readings to understand certain parts of each chpater.Although it was extremely interesting, I had to persistently apply myself to be clear in the concepts.I am happy that I did so and got through the book nicely.

### TASK 5

We then dived into pytorch and tensorflow tutorials.They are the librarys used to create deep learning models.We were given the freedom to choose one of the two. I decided to go ahead with pytorch.
I maily used the [pytorch official tutorials](https://pytorch.org/tutorials/) to learn and get comfortable using pytorch.

We were also asked to try and create a deep learnig model on some [OpenAI gym](https://gym.openai.com/) environmnets for practice as we would be using a similar emvironment for  our game of 2048.

### TASK 6

We then arrived at an important stage of the project.We had to read and understand a reserch paper on [Playing ATARI with deep reinforcemnt learnng](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) which we would be using as a guide.

The paper reasoned why we use a combination of deep and reinforcemt learning on tasks.It described in detail the implementation of the dqn algorithm on 7 ATARI games. As our game 2048 was quite similar to the ATARI games, we used this research paper throughout the coding part.

We also read many articles and projects on variants of dqn like ddqn,dddqn,etc and the benefits like improved performance,lesser computations,simplified flow by using the different variants.

# TASK 6

I then set out to give the project it's online form.

This was where the programming started.I spent almost a whole week to revise evrything and be clear with what I was going ot do.I created many checklists and points on what I should be doing when.

Once, I was done with all this,I finally started programming.I knew that it woud take a full day to complete it.Amusingly, I started at night and ended up completing it in the morning.Then came the debugging and improving part. I had meets almost daily night for about three-four days with my mentor Ankit. We discussed my doubts, places where I was stuck and the improvements that I should make.
After this three-four day period, the program was complete.It was now time to train the agent.I was able to so do some preliminary training. 

The agent works great! With some more training and tuning of the parameters to find the optimal ones, the agent will be able to match or even beat human scores.


### Conclusion 

It was a wonderful project for me.It was a great learning experience. The satisafction and joy at the end is on a whole differny level.The interactions with the mentors and other mentees was great.The mentors really helped me a lot and I credit the success of the project to them. 

I enjoyed every single part of the project:)


# Thank You























 
